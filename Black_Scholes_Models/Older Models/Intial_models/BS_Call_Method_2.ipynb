{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"BS_Call_Method_2.ipynb","provenance":[{"file_id":"17NMeq2P3kUz0GYHUtov-8GOEP-HSyXD2","timestamp":1628548968770},{"file_id":"1KrVZ8d4GaQPJBJQzlWKCOqzYol041evA","timestamp":1628525472131},{"file_id":"1ftK02qhTUzD0ed67r6BPXUNpLYKygiX3","timestamp":1628520490953}],"collapsed_sections":[],"authorship_tag":"ABX9TyOGk/7azO27IbFt6F4FdofA"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"c6f97d7487134944b46695efc7f5561b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_5ef9bd2c1ac74bfeadaab11c5804acb1","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_35f555a9c36e4b6ea25b64b98d489f66","IPY_MODEL_4fb61f84e6ad48668ee032d100b82554"]}},"5ef9bd2c1ac74bfeadaab11c5804acb1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":"row wrap","width":"100%","min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":"inline-flex","left":null}},"35f555a9c36e4b6ea25b64b98d489f66":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_a2e2719e79ae4856b971316a455449da","_dom_classes":[],"description":"Validation sanity check: 100%","_model_name":"FloatProgressModel","bar_style":"info","max":2,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":2,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_da2936ade49c4eeb8f244f21c009a0e4"}},"4fb61f84e6ad48668ee032d100b82554":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_fa11c0d35c804931a2e4d9adf03d52b8","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 2/2 [00:00&lt;00:00,  8.15it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_6982768b818e4479900eaaffe6848edc"}},"a2e2719e79ae4856b971316a455449da":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"da2936ade49c4eeb8f244f21c009a0e4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":"2","_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"fa11c0d35c804931a2e4d9adf03d52b8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"6982768b818e4479900eaaffe6848edc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"96ba0537cb6e4f14b84522fc12c97b0a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_58652738bfde418fb1ca8f6ede3fd5fe","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_12dee8206fd84192971fe2c0ae97b3f8","IPY_MODEL_a6ead4e4f498429b84582333b0c15360"]}},"58652738bfde418fb1ca8f6ede3fd5fe":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":"row wrap","width":"100%","min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":"inline-flex","left":null}},"12dee8206fd84192971fe2c0ae97b3f8":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_eba887288f484b5db7d50bf98345dc3b","_dom_classes":[],"description":"Epoch 0:   0%","_model_name":"FloatProgressModel","bar_style":"info","max":10,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":0,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_97e59e0dead6458c9e2c39a982290f5b"}},"a6ead4e4f498429b84582333b0c15360":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_7c94a8f0142d4b67b781f40209cafb1f","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 0/10 [00:00&lt;?, ?it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_7dd3863a5fe04a0cbfffe66e51de75b5"}},"eba887288f484b5db7d50bf98345dc3b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"97e59e0dead6458c9e2c39a982290f5b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":"2","_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7c94a8f0142d4b67b781f40209cafb1f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"7dd3863a5fe04a0cbfffe66e51de75b5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"id":"LChUgCUa8Njk","executionInfo":{"status":"ok","timestamp":1628549018996,"user_tz":-60,"elapsed":357,"user":{"displayName":"Akshay Parmar","photoUrl":"","userId":"04463184220884570036"}}},"source":["  # Fix the strike price \n","# Main thing \n","# Create samples such that ;\n","# '''\n","# The four variables make a sample x is a data point x = (t, S, r, sigma) is data points. \n","# No stable results -> then normalise the varaibles. \n","#        t -> (0,2) only discrete number of days / 365. T is measure in years. \n","#        S -> (50,150) stock prices. \n","#        r -> [0%,1%] \n","#        sigma (volatility) -> [1%,50%] -> standard deviation of the log of the returns. \n","# We will use uniform distribution. \n","# '''\n","\n"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"8MWiRT8gCGz3","executionInfo":{"status":"ok","timestamp":1628549020347,"user_tz":-60,"elapsed":13,"user":{"displayName":"Akshay Parmar","photoUrl":"","userId":"04463184220884570036"}}},"source":["# Work on this one feature at a time.  *\n","\n","# Let say we want to make 500 samples to be safe. *\n","\n","# Create 1 feature at a time column by column *\n","\n","# then stack the columns together to get a matrix that is mxn and is check mate *\n","\n","# create pricing function, use jacaboian and hessian to generate the data. *\n","\n","# Do same procedure for the model. \n","\n","# investigate normalization after. Also how to print graphs with epochs and data. \n","\n","# Read the black scholes paper -> find ideas to relate to yours. "],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IMtM0dA6KIRk","executionInfo":{"status":"ok","timestamp":1628550251431,"user_tz":-60,"elapsed":13213,"user":{"displayName":"Akshay Parmar","photoUrl":"","userId":"04463184220884570036"}},"outputId":"8eecc07d-bcae-4824-de65-2f2187d8f1af"},"source":["pip install pytorch-lightning"],"execution_count":42,"outputs":[{"output_type":"stream","text":["Collecting pytorch-lightning\n","  Downloading pytorch_lightning-1.4.1-py3-none-any.whl (915 kB)\n","\u001b[K     |████████████████████████████████| 915 kB 4.0 MB/s \n","\u001b[?25hCollecting tensorboard!=2.5.0,>=2.2.0\n","  Downloading tensorboard-2.6.0-py3-none-any.whl (5.6 MB)\n","\u001b[K     |████████████████████████████████| 5.6 MB 14.8 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (4.41.1)\n","Collecting pyDeprecate==0.3.1\n","  Downloading pyDeprecate-0.3.1-py3-none-any.whl (10 kB)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (3.7.4.3)\n","Collecting fsspec[http]!=2021.06.0,>=2021.05.0\n","  Downloading fsspec-2021.7.0-py3-none-any.whl (118 kB)\n","\u001b[K     |████████████████████████████████| 118 kB 58.7 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (1.19.5)\n","Collecting torchmetrics>=0.4.0\n","  Downloading torchmetrics-0.4.1-py3-none-any.whl (234 kB)\n","\u001b[K     |████████████████████████████████| 234 kB 67.5 MB/s \n","\u001b[?25hCollecting PyYAML>=5.1\n","  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n","\u001b[K     |████████████████████████████████| 636 kB 54.2 MB/s \n","\u001b[?25hRequirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (21.0)\n","Requirement already satisfied: torch>=1.6 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (1.9.0+cu102)\n","Collecting future>=0.17.1\n","  Downloading future-0.18.2.tar.gz (829 kB)\n","\u001b[K     |████████████████████████████████| 829 kB 60.9 MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (2.23.0)\n","Collecting aiohttp\n","  Downloading aiohttp-3.7.4.post0-cp37-cp37m-manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[K     |████████████████████████████████| 1.3 MB 58.0 MB/s \n","\u001b[?25hRequirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=17.0->pytorch-lightning) (2.4.7)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (0.4.4)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (57.2.0)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (0.6.1)\n","Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (1.34.1)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (0.12.0)\n","Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (3.17.3)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (3.3.4)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (0.36.2)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (1.0.1)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (1.8.0)\n","Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (1.32.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py>=0.4->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (1.15.0)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (4.2.2)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (4.7.2)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (0.2.8)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (1.3.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (4.6.1)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (0.4.8)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (2021.5.30)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (2.10)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (3.1.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (21.2.0)\n","Collecting multidict<7.0,>=4.5\n","  Downloading multidict-5.1.0-cp37-cp37m-manylinux2014_x86_64.whl (142 kB)\n","\u001b[K     |████████████████████████████████| 142 kB 50.2 MB/s \n","\u001b[?25hCollecting async-timeout<4.0,>=3.0\n","  Downloading async_timeout-3.0.1-py3-none-any.whl (8.2 kB)\n","Collecting yarl<2.0,>=1.0\n","  Downloading yarl-1.6.3-cp37-cp37m-manylinux2014_x86_64.whl (294 kB)\n","\u001b[K     |████████████████████████████████| 294 kB 51.0 MB/s \n","\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (3.5.0)\n","Building wheels for collected packages: future\n","  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for future: filename=future-0.18.2-py3-none-any.whl size=491070 sha256=ef455b7d2d0636b8be6ed12e408084625f0efad79e1f99f332bd633fff826e28\n","  Stored in directory: /root/.cache/pip/wheels/56/b0/fe/4410d17b32f1f0c3cf54cdfb2bc04d7b4b8f4ae377e2229ba0\n","Successfully built future\n","Installing collected packages: multidict, yarl, async-timeout, fsspec, aiohttp, torchmetrics, tensorboard, PyYAML, pyDeprecate, future, pytorch-lightning\n","  Attempting uninstall: tensorboard\n","    Found existing installation: tensorboard 2.5.0\n","    Uninstalling tensorboard-2.5.0:\n","      Successfully uninstalled tensorboard-2.5.0\n","  Attempting uninstall: PyYAML\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","  Attempting uninstall: future\n","    Found existing installation: future 0.16.0\n","    Uninstalling future-0.16.0:\n","      Successfully uninstalled future-0.16.0\n","Successfully installed PyYAML-5.4.1 aiohttp-3.7.4.post0 async-timeout-3.0.1 fsspec-2021.7.0 future-0.18.2 multidict-5.1.0 pyDeprecate-0.3.1 pytorch-lightning-1.4.1 tensorboard-2.6.0 torchmetrics-0.4.1 yarl-1.6.3\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Qer5lnOgDi3J","executionInfo":{"status":"ok","timestamp":1628550269939,"user_tz":-60,"elapsed":459,"user":{"displayName":"Akshay Parmar","photoUrl":"","userId":"04463184220884570036"}}},"source":["import numpy as np\n","import scipy.stats as si\n","import sympy as sy\n","from sympy.stats import Normal, cdf\n","from sympy import init_printing\n","init_printing()\n","import torch \n","from torch import autograd\n","from torch import nn # import neural network \n","from torch import optim \n","from torchvision import datasets, transforms\n","from torch.utils.data import random_split, DataLoader\n","import pytorch_lightning as pl\n"],"execution_count":43,"outputs":[]},{"cell_type":"code","metadata":{"id":"st1e-dnFDjHv","executionInfo":{"status":"ok","timestamp":1628549025777,"user_tz":-60,"elapsed":145,"user":{"displayName":"Akshay Parmar","photoUrl":"","userId":"04463184220884570036"}}},"source":[""],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rw_yvT5lEQPp","executionInfo":{"status":"ok","timestamp":1628549028719,"user_tz":-60,"elapsed":809,"user":{"displayName":"Akshay Parmar","photoUrl":"","userId":"04463184220884570036"}},"outputId":"1c8b0209-e6ce-45b0-acd9-e9e7a0e602c2"},"source":["# stock price - between [50,150]\n","\n","a,b = 500 ,1 #dimension of the pytorch tensor to be generated\n","low , high = 50 , 150 #range of uniform distribution\n","torch.manual_seed(50) #Fx the values\n","S_t = torch.distributions.uniform.Uniform(low, high).sample([a,b]) # samples from low and high values. a,b are the dimensions\n","\n","Stock = S_t.view(500,1)\n","print(Stock)"],"execution_count":5,"outputs":[{"output_type":"stream","text":["tensor([[111.8022],\n","        [ 56.8693],\n","        [ 88.9275],\n","        [ 54.0412],\n","        [ 90.1323],\n","        [ 64.4163],\n","        [ 96.0457],\n","        [ 98.7675],\n","        [109.2665],\n","        [146.3383],\n","        [ 62.3002],\n","        [ 90.4769],\n","        [ 99.8482],\n","        [149.8734],\n","        [110.4864],\n","        [102.2903],\n","        [119.7392],\n","        [ 75.0510],\n","        [ 86.2393],\n","        [ 96.2094],\n","        [121.4548],\n","        [100.5850],\n","        [ 55.1794],\n","        [ 74.9155],\n","        [ 73.9515],\n","        [ 92.3287],\n","        [ 50.2160],\n","        [118.4802],\n","        [124.9681],\n","        [ 74.8874],\n","        [ 84.9019],\n","        [ 69.5258],\n","        [ 77.9231],\n","        [ 75.2583],\n","        [ 87.9211],\n","        [126.8585],\n","        [119.0705],\n","        [125.2633],\n","        [ 61.8385],\n","        [136.9878],\n","        [133.9136],\n","        [ 55.3168],\n","        [ 67.0496],\n","        [ 79.1351],\n","        [106.8239],\n","        [ 53.7998],\n","        [ 77.1507],\n","        [119.8719],\n","        [ 59.4418],\n","        [117.1934],\n","        [ 87.8224],\n","        [137.3787],\n","        [122.6670],\n","        [144.8607],\n","        [ 93.8819],\n","        [ 95.8858],\n","        [ 53.5889],\n","        [ 85.2484],\n","        [ 53.8893],\n","        [ 88.8037],\n","        [ 63.1897],\n","        [100.1778],\n","        [130.7733],\n","        [143.2230],\n","        [106.8028],\n","        [100.3421],\n","        [ 70.7407],\n","        [ 97.7853],\n","        [ 92.0294],\n","        [ 90.1439],\n","        [ 54.3583],\n","        [114.9041],\n","        [140.0677],\n","        [132.7425],\n","        [ 87.8462],\n","        [125.1778],\n","        [ 78.3886],\n","        [122.1972],\n","        [134.2083],\n","        [ 74.7435],\n","        [118.3435],\n","        [ 55.5103],\n","        [128.2412],\n","        [129.0052],\n","        [145.9618],\n","        [110.6487],\n","        [109.2576],\n","        [122.9967],\n","        [147.6825],\n","        [146.8043],\n","        [ 64.9420],\n","        [148.2564],\n","        [129.2070],\n","        [108.4153],\n","        [146.2802],\n","        [ 81.9244],\n","        [107.4963],\n","        [ 65.3814],\n","        [ 75.4013],\n","        [147.0265],\n","        [100.1963],\n","        [ 80.1839],\n","        [138.3242],\n","        [ 69.2095],\n","        [126.8634],\n","        [ 75.2355],\n","        [ 86.6760],\n","        [ 54.8360],\n","        [128.2946],\n","        [120.3202],\n","        [122.6515],\n","        [107.9401],\n","        [ 64.1226],\n","        [131.0472],\n","        [142.8371],\n","        [144.4445],\n","        [115.3758],\n","        [103.4441],\n","        [130.2519],\n","        [104.8402],\n","        [107.3779],\n","        [ 92.2535],\n","        [125.0640],\n","        [116.4118],\n","        [ 81.2952],\n","        [143.9452],\n","        [ 81.5835],\n","        [144.8639],\n","        [ 76.6189],\n","        [ 65.3774],\n","        [ 95.0832],\n","        [126.0155],\n","        [132.6007],\n","        [ 99.7973],\n","        [ 59.9247],\n","        [ 77.0531],\n","        [ 82.9797],\n","        [ 59.2933],\n","        [101.4269],\n","        [100.8180],\n","        [125.3950],\n","        [117.1841],\n","        [135.4686],\n","        [116.6184],\n","        [ 60.2182],\n","        [ 84.0601],\n","        [ 80.0403],\n","        [116.0126],\n","        [ 72.6588],\n","        [134.4357],\n","        [130.8307],\n","        [130.5478],\n","        [105.2958],\n","        [ 56.2752],\n","        [141.5727],\n","        [ 91.6102],\n","        [ 89.2605],\n","        [131.4030],\n","        [142.5525],\n","        [ 54.3447],\n","        [105.9774],\n","        [128.6119],\n","        [126.0941],\n","        [ 50.6839],\n","        [ 54.6233],\n","        [120.8175],\n","        [ 89.3651],\n","        [ 72.9761],\n","        [ 80.0226],\n","        [106.2552],\n","        [ 84.4200],\n","        [119.3513],\n","        [129.7872],\n","        [ 52.1539],\n","        [ 62.8108],\n","        [ 78.9419],\n","        [129.1450],\n","        [ 78.5752],\n","        [114.6720],\n","        [133.5209],\n","        [ 76.5139],\n","        [ 92.4880],\n","        [148.8817],\n","        [ 56.8241],\n","        [ 81.4024],\n","        [ 51.5579],\n","        [ 70.9069],\n","        [ 77.0626],\n","        [147.3270],\n","        [ 80.6339],\n","        [136.7362],\n","        [ 98.3800],\n","        [110.2844],\n","        [109.8072],\n","        [147.2259],\n","        [144.8073],\n","        [136.9628],\n","        [133.0942],\n","        [ 79.6517],\n","        [118.9982],\n","        [122.2607],\n","        [125.2726],\n","        [ 94.9158],\n","        [ 78.8612],\n","        [100.4069],\n","        [146.0580],\n","        [118.3132],\n","        [108.1192],\n","        [ 55.2039],\n","        [128.0969],\n","        [ 51.9804],\n","        [ 90.9344],\n","        [117.7581],\n","        [ 51.7293],\n","        [102.6645],\n","        [134.8196],\n","        [ 86.8288],\n","        [ 87.9405],\n","        [ 55.0572],\n","        [ 87.7636],\n","        [148.0243],\n","        [ 85.6191],\n","        [129.9864],\n","        [108.6369],\n","        [ 99.8216],\n","        [116.5699],\n","        [101.7567],\n","        [ 90.9188],\n","        [112.1715],\n","        [101.1611],\n","        [148.7027],\n","        [132.1578],\n","        [ 57.6714],\n","        [ 81.1708],\n","        [ 50.4924],\n","        [123.6733],\n","        [141.6728],\n","        [ 72.2994],\n","        [104.9301],\n","        [ 75.7377],\n","        [110.8595],\n","        [100.4226],\n","        [ 73.2822],\n","        [ 93.2797],\n","        [122.5677],\n","        [105.2604],\n","        [128.5153],\n","        [ 85.8705],\n","        [108.3822],\n","        [ 91.5161],\n","        [139.2665],\n","        [139.2617],\n","        [111.3398],\n","        [102.6509],\n","        [ 72.4255],\n","        [ 62.6479],\n","        [142.3723],\n","        [104.7455],\n","        [ 76.2650],\n","        [ 52.2022],\n","        [ 75.8541],\n","        [ 92.7972],\n","        [111.6999],\n","        [103.0815],\n","        [103.9908],\n","        [ 95.5559],\n","        [125.3951],\n","        [124.1145],\n","        [100.0103],\n","        [102.2442],\n","        [ 78.4636],\n","        [130.9439],\n","        [ 52.1864],\n","        [ 79.2834],\n","        [ 80.3853],\n","        [ 82.6075],\n","        [112.9013],\n","        [ 56.7095],\n","        [134.6640],\n","        [133.2270],\n","        [147.1945],\n","        [ 67.7449],\n","        [ 87.6957],\n","        [109.3284],\n","        [ 76.2018],\n","        [137.2035],\n","        [ 87.0771],\n","        [ 83.4996],\n","        [108.8997],\n","        [ 53.9730],\n","        [ 98.0554],\n","        [144.7979],\n","        [ 54.2521],\n","        [104.6309],\n","        [127.8140],\n","        [101.9649],\n","        [107.2679],\n","        [111.4467],\n","        [ 67.9675],\n","        [ 54.4521],\n","        [130.1495],\n","        [ 61.0950],\n","        [104.7773],\n","        [147.4479],\n","        [ 72.2004],\n","        [100.2873],\n","        [ 73.4145],\n","        [ 80.2168],\n","        [119.4224],\n","        [ 62.4641],\n","        [ 55.9665],\n","        [109.9360],\n","        [134.5817],\n","        [124.5171],\n","        [126.4484],\n","        [ 92.1489],\n","        [ 93.8071],\n","        [148.4803],\n","        [108.3762],\n","        [109.1878],\n","        [142.2674],\n","        [137.7342],\n","        [117.1939],\n","        [117.0930],\n","        [108.5860],\n","        [103.5191],\n","        [147.3047],\n","        [ 72.1576],\n","        [109.4228],\n","        [116.9283],\n","        [ 96.3231],\n","        [109.5111],\n","        [147.5036],\n","        [141.1617],\n","        [142.2836],\n","        [ 54.5252],\n","        [ 58.6580],\n","        [106.1718],\n","        [103.4511],\n","        [135.8890],\n","        [128.1897],\n","        [ 66.6636],\n","        [ 58.4877],\n","        [ 59.0176],\n","        [147.3996],\n","        [ 53.4774],\n","        [ 84.3961],\n","        [116.3980],\n","        [125.7789],\n","        [117.9872],\n","        [ 98.1045],\n","        [142.7933],\n","        [ 75.4299],\n","        [117.4753],\n","        [ 59.4801],\n","        [ 75.1450],\n","        [143.0165],\n","        [ 68.1804],\n","        [108.8841],\n","        [127.4407],\n","        [ 54.0845],\n","        [139.4023],\n","        [ 52.0398],\n","        [ 54.0769],\n","        [120.8574],\n","        [110.5054],\n","        [104.5901],\n","        [133.4898],\n","        [119.9262],\n","        [ 94.8616],\n","        [ 68.0251],\n","        [ 85.7291],\n","        [ 77.3204],\n","        [121.9503],\n","        [109.8165],\n","        [137.6191],\n","        [ 89.1767],\n","        [123.1689],\n","        [119.1940],\n","        [145.1964],\n","        [ 99.4486],\n","        [101.5335],\n","        [ 64.1441],\n","        [ 51.3133],\n","        [120.1846],\n","        [126.6353],\n","        [144.3992],\n","        [143.8781],\n","        [120.4172],\n","        [104.2422],\n","        [135.1328],\n","        [ 54.7459],\n","        [ 81.7170],\n","        [101.2612],\n","        [100.6569],\n","        [ 90.1831],\n","        [136.4584],\n","        [ 74.5227],\n","        [ 51.1405],\n","        [109.9712],\n","        [ 96.9644],\n","        [ 85.0379],\n","        [102.4124],\n","        [ 53.7898],\n","        [ 87.1455],\n","        [117.4004],\n","        [ 84.9680],\n","        [110.0722],\n","        [100.5204],\n","        [145.5949],\n","        [ 83.9513],\n","        [138.7368],\n","        [ 65.6630],\n","        [142.4046],\n","        [132.4595],\n","        [ 52.8644],\n","        [132.6125],\n","        [ 86.8241],\n","        [120.8516],\n","        [ 60.6319],\n","        [ 88.4411],\n","        [ 93.5977],\n","        [ 85.8375],\n","        [ 84.0902],\n","        [ 68.9268],\n","        [111.5305],\n","        [117.9519],\n","        [126.6835],\n","        [ 84.9414],\n","        [143.5313],\n","        [ 82.0657],\n","        [120.4643],\n","        [ 86.1112],\n","        [ 66.8937],\n","        [ 51.7054],\n","        [ 59.0462],\n","        [ 96.4847],\n","        [126.5677],\n","        [ 61.1419],\n","        [100.7825],\n","        [124.9712],\n","        [141.2714],\n","        [115.5966],\n","        [ 50.8120],\n","        [ 91.7732],\n","        [145.6934],\n","        [137.1774],\n","        [145.7421],\n","        [101.8496],\n","        [ 83.9900],\n","        [ 54.4305],\n","        [135.2440],\n","        [ 69.5474],\n","        [119.5697],\n","        [134.6175],\n","        [135.7585],\n","        [ 62.3534],\n","        [131.1476],\n","        [149.6744],\n","        [ 74.0584],\n","        [ 71.7353],\n","        [148.3557],\n","        [120.1973],\n","        [ 53.4443],\n","        [120.2942],\n","        [119.0254],\n","        [ 88.2755],\n","        [106.6166],\n","        [ 52.6067],\n","        [ 96.0339],\n","        [123.8529],\n","        [ 78.0663],\n","        [ 96.5802],\n","        [ 66.9820],\n","        [123.0822],\n","        [140.8112],\n","        [ 86.9601],\n","        [122.4277],\n","        [115.0167],\n","        [ 77.0782],\n","        [ 91.6684],\n","        [ 54.7505],\n","        [ 81.1140],\n","        [147.7842],\n","        [123.2092],\n","        [ 82.2490],\n","        [ 98.0780],\n","        [ 89.8756],\n","        [136.9626],\n","        [ 75.6066],\n","        [ 76.4065],\n","        [146.2772],\n","        [ 72.5974],\n","        [ 70.1342],\n","        [ 69.5361],\n","        [144.6640],\n","        [132.7592],\n","        [ 59.1280],\n","        [ 98.1553],\n","        [106.5278]])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"JacHhTOGEq_H","executionInfo":{"status":"ok","timestamp":1628549030303,"user_tz":-60,"elapsed":366,"user":{"displayName":"Akshay Parmar","photoUrl":"","userId":"04463184220884570036"}}},"source":["# Time -[ between 0 and 2]\n","\n","a,b = 500 ,1 #dimension of the pytorch tensor to be generated\n","low_t , high_t = 0, 730 #range of uniform distribution by number of days [0, 2]Years\n","torch.manual_seed(56) #Fx the values\n","t_t= torch.randint(low_t, high_t, size= (500,1) )  # https://pytorch.org/docs/stable/generated/torch.randint.html - generates uniformaly integers\n","\n","t = t_t / 365 # to get a more reliable spread of results\n","\n","# time for maturity \n","#print(t)\n","Time = t.view(500,1)\n","#print(Time)"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"dIF9taBiUOMp","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628549034293,"user_tz":-60,"elapsed":340,"user":{"displayName":"Akshay Parmar","photoUrl":"","userId":"04463184220884570036"}},"outputId":"f65df11e-a1d6-441c-90b7-5b75955daad8"},"source":["\n","a,b = 500 ,1 #dimension of the pytorch tensor to be generated\n","low , high = 0 , 0.01 #range of uniform distribution [0%,1%]\n","torch.manual_seed(12) #Fx the values\n","r = torch.distributions.uniform.Uniform(low, high).sample([a,b]) # samples from low and high values. a,b are the dimensions\n","\n","Rate = r.view(500,1)\n","print(Rate)"],"execution_count":7,"outputs":[{"output_type":"stream","text":["tensor([[4.6569e-03],\n","        [2.3277e-03],\n","        [4.5272e-03],\n","        [5.8711e-03],\n","        [4.0864e-03],\n","        [1.2717e-03],\n","        [6.3728e-03],\n","        [2.4206e-03],\n","        [7.3119e-03],\n","        [7.2244e-03],\n","        [1.9924e-03],\n","        [6.9483e-03],\n","        [5.8300e-03],\n","        [6.3183e-03],\n","        [5.5589e-03],\n","        [1.2625e-03],\n","        [9.7903e-03],\n","        [8.4427e-03],\n","        [1.2559e-03],\n","        [4.4562e-03],\n","        [6.6006e-03],\n","        [5.5381e-04],\n","        [1.5729e-03],\n","        [8.1367e-03],\n","        [7.2163e-03],\n","        [2.7173e-03],\n","        [3.0030e-03],\n","        [6.0994e-03],\n","        [5.7837e-03],\n","        [6.0834e-03],\n","        [4.3386e-03],\n","        [8.8131e-03],\n","        [3.2163e-03],\n","        [2.6044e-03],\n","        [2.5662e-03],\n","        [1.8722e-03],\n","        [6.4234e-03],\n","        [1.7856e-03],\n","        [1.4349e-03],\n","        [7.4904e-03],\n","        [7.2748e-03],\n","        [1.6413e-03],\n","        [3.2731e-03],\n","        [1.2394e-03],\n","        [6.1380e-03],\n","        [4.5347e-03],\n","        [7.6589e-03],\n","        [1.7998e-03],\n","        [3.3378e-03],\n","        [9.5258e-03],\n","        [8.9188e-03],\n","        [9.8594e-03],\n","        [6.3482e-03],\n","        [8.8115e-03],\n","        [9.3908e-03],\n","        [1.1733e-03],\n","        [1.3422e-03],\n","        [9.4047e-03],\n","        [6.8025e-03],\n","        [5.5559e-03],\n","        [8.7132e-03],\n","        [7.8215e-04],\n","        [8.5778e-03],\n","        [7.5400e-03],\n","        [6.6977e-03],\n","        [5.8174e-03],\n","        [3.8287e-03],\n","        [7.1626e-03],\n","        [8.9302e-03],\n","        [5.5965e-03],\n","        [2.8026e-03],\n","        [2.4760e-03],\n","        [4.7377e-03],\n","        [1.3057e-03],\n","        [2.0237e-03],\n","        [6.3868e-03],\n","        [9.9918e-04],\n","        [9.6145e-03],\n","        [5.3495e-03],\n","        [7.1406e-03],\n","        [5.6170e-03],\n","        [9.3177e-04],\n","        [7.5537e-03],\n","        [2.4570e-03],\n","        [4.5643e-03],\n","        [7.5540e-03],\n","        [4.2481e-03],\n","        [8.8401e-03],\n","        [3.2807e-03],\n","        [8.1618e-03],\n","        [5.5743e-03],\n","        [8.0262e-03],\n","        [5.6611e-03],\n","        [2.6652e-03],\n","        [6.7312e-03],\n","        [6.5486e-03],\n","        [1.7007e-03],\n","        [1.1221e-03],\n","        [3.0764e-05],\n","        [9.9427e-03],\n","        [5.7380e-03],\n","        [5.5909e-03],\n","        [5.2530e-03],\n","        [3.0211e-03],\n","        [8.6720e-03],\n","        [8.2054e-03],\n","        [1.4439e-03],\n","        [7.1165e-03],\n","        [8.4354e-03],\n","        [4.5909e-03],\n","        [5.3825e-03],\n","        [5.9378e-03],\n","        [8.5118e-04],\n","        [1.7838e-03],\n","        [9.5099e-03],\n","        [2.6122e-04],\n","        [5.9063e-03],\n","        [1.6631e-04],\n","        [3.4400e-03],\n","        [4.3865e-03],\n","        [5.3556e-03],\n","        [2.5917e-03],\n","        [7.0026e-03],\n","        [6.0630e-03],\n","        [8.2040e-04],\n","        [5.4303e-03],\n","        [9.4201e-03],\n","        [9.1870e-03],\n","        [2.6959e-03],\n","        [7.8865e-03],\n","        [1.4075e-03],\n","        [9.5172e-03],\n","        [6.7836e-03],\n","        [6.7655e-03],\n","        [1.2871e-03],\n","        [3.2810e-03],\n","        [5.4226e-04],\n","        [7.4241e-03],\n","        [7.9089e-04],\n","        [3.0929e-03],\n","        [4.5903e-03],\n","        [7.0398e-03],\n","        [6.3120e-03],\n","        [6.5052e-03],\n","        [8.9198e-03],\n","        [5.1193e-03],\n","        [4.4257e-03],\n","        [3.0880e-03],\n","        [3.7612e-03],\n","        [9.1995e-04],\n","        [8.1285e-03],\n","        [9.5422e-03],\n","        [8.0833e-03],\n","        [7.4171e-03],\n","        [3.5903e-03],\n","        [8.8538e-04],\n","        [9.7467e-03],\n","        [3.4973e-03],\n","        [3.0590e-03],\n","        [1.2533e-03],\n","        [1.7069e-03],\n","        [6.0185e-03],\n","        [7.9108e-03],\n","        [6.0712e-04],\n","        [5.9254e-04],\n","        [4.3266e-03],\n","        [8.0525e-04],\n","        [8.9186e-03],\n","        [5.0915e-03],\n","        [1.3726e-03],\n","        [6.2866e-03],\n","        [8.6563e-03],\n","        [5.7241e-03],\n","        [1.3932e-03],\n","        [5.8195e-03],\n","        [1.2443e-03],\n","        [7.8594e-03],\n","        [4.5167e-03],\n","        [6.1291e-03],\n","        [4.3318e-03],\n","        [9.8860e-04],\n","        [6.3860e-03],\n","        [9.2534e-03],\n","        [4.0014e-03],\n","        [3.1829e-03],\n","        [9.3000e-04],\n","        [4.4078e-03],\n","        [9.8530e-03],\n","        [3.6548e-03],\n","        [3.5212e-03],\n","        [8.4172e-03],\n","        [9.2552e-04],\n","        [4.2649e-03],\n","        [3.3510e-03],\n","        [4.8541e-03],\n","        [1.7951e-03],\n","        [5.1280e-03],\n","        [5.6453e-03],\n","        [5.8909e-03],\n","        [2.0159e-03],\n","        [6.1555e-03],\n","        [6.3055e-04],\n","        [5.0992e-03],\n","        [5.5482e-03],\n","        [3.6661e-03],\n","        [4.5996e-03],\n","        [5.0251e-03],\n","        [7.6503e-03],\n","        [9.4470e-03],\n","        [4.7464e-04],\n","        [8.8766e-03],\n","        [6.7043e-03],\n","        [9.8796e-03],\n","        [9.4636e-03],\n","        [3.2712e-03],\n","        [2.6744e-03],\n","        [8.3670e-03],\n","        [7.8903e-03],\n","        [9.1555e-03],\n","        [2.8732e-03],\n","        [6.2484e-03],\n","        [3.2498e-03],\n","        [1.2889e-03],\n","        [8.1177e-03],\n","        [6.0549e-03],\n","        [9.0028e-03],\n","        [7.5151e-03],\n","        [1.5053e-03],\n","        [2.6780e-03],\n","        [6.5432e-03],\n","        [8.7755e-03],\n","        [8.2581e-04],\n","        [9.8060e-03],\n","        [8.0983e-03],\n","        [4.6112e-03],\n","        [2.0913e-04],\n","        [2.8920e-03],\n","        [8.4564e-03],\n","        [6.7140e-03],\n","        [5.7798e-03],\n","        [7.7958e-04],\n","        [2.8130e-04],\n","        [6.2821e-04],\n","        [5.0141e-03],\n","        [4.3218e-03],\n","        [2.2069e-03],\n","        [9.7490e-03],\n","        [1.0015e-04],\n","        [2.8268e-04],\n","        [6.1235e-04],\n","        [2.5306e-03],\n","        [5.3462e-03],\n","        [3.5515e-03],\n","        [5.3734e-03],\n","        [8.8138e-03],\n","        [1.2175e-03],\n","        [2.7122e-03],\n","        [9.7523e-03],\n","        [3.9152e-03],\n","        [3.2165e-03],\n","        [8.2584e-03],\n","        [9.5770e-03],\n","        [3.3790e-03],\n","        [1.2776e-03],\n","        [9.9339e-03],\n","        [9.1984e-03],\n","        [6.8936e-03],\n","        [5.7207e-03],\n","        [4.4163e-03],\n","        [2.2116e-03],\n","        [4.8856e-04],\n","        [9.8939e-03],\n","        [6.7223e-03],\n","        [9.5460e-03],\n","        [9.4945e-03],\n","        [5.8301e-04],\n","        [6.6746e-03],\n","        [1.5353e-03],\n","        [8.1107e-03],\n","        [9.5678e-03],\n","        [9.6629e-03],\n","        [8.5742e-03],\n","        [6.3713e-03],\n","        [3.5372e-03],\n","        [6.7270e-03],\n","        [2.0756e-03],\n","        [4.9396e-03],\n","        [7.9779e-03],\n","        [1.0282e-03],\n","        [5.9092e-03],\n","        [8.9574e-03],\n","        [6.8857e-03],\n","        [6.8447e-03],\n","        [6.5575e-03],\n","        [2.4951e-03],\n","        [7.7200e-03],\n","        [7.9632e-03],\n","        [3.9875e-03],\n","        [5.7039e-04],\n","        [4.5957e-03],\n","        [7.9565e-03],\n","        [5.3598e-03],\n","        [7.9190e-03],\n","        [2.3655e-03],\n","        [2.0126e-03],\n","        [1.0809e-03],\n","        [1.2545e-03],\n","        [5.1568e-03],\n","        [2.1058e-03],\n","        [1.3525e-03],\n","        [3.4714e-03],\n","        [6.1840e-03],\n","        [2.1194e-03],\n","        [5.7274e-03],\n","        [8.8733e-04],\n","        [7.3244e-03],\n","        [2.1630e-03],\n","        [9.5457e-03],\n","        [9.2192e-03],\n","        [1.7541e-03],\n","        [9.5285e-04],\n","        [9.4797e-03],\n","        [3.0853e-03],\n","        [4.0150e-03],\n","        [4.1848e-03],\n","        [8.0866e-03],\n","        [5.4796e-04],\n","        [2.5711e-03],\n","        [8.5941e-04],\n","        [6.2539e-03],\n","        [1.6981e-03],\n","        [9.0549e-03],\n","        [9.6344e-03],\n","        [8.4477e-04],\n","        [7.4867e-03],\n","        [1.2881e-03],\n","        [1.2998e-03],\n","        [4.7148e-03],\n","        [2.4830e-03],\n","        [6.9088e-03],\n","        [8.0008e-03],\n","        [4.0990e-03],\n","        [4.4038e-03],\n","        [9.7962e-03],\n","        [9.1916e-03],\n","        [3.9974e-03],\n","        [4.2370e-03],\n","        [5.3191e-03],\n","        [6.5928e-03],\n","        [5.7228e-03],\n","        [1.1069e-03],\n","        [3.2478e-03],\n","        [3.1500e-03],\n","        [2.9880e-03],\n","        [5.2846e-03],\n","        [3.3306e-03],\n","        [1.0687e-03],\n","        [2.5909e-04],\n","        [4.1681e-04],\n","        [8.2868e-03],\n","        [9.8744e-03],\n","        [7.7010e-03],\n","        [9.3810e-03],\n","        [9.1231e-03],\n","        [6.5881e-04],\n","        [5.3043e-03],\n","        [3.8470e-03],\n","        [1.7885e-03],\n","        [1.0916e-03],\n","        [7.0954e-03],\n","        [7.8134e-03],\n","        [8.6352e-03],\n","        [4.9894e-03],\n","        [7.7390e-03],\n","        [9.5098e-03],\n","        [4.9793e-03],\n","        [7.3731e-03],\n","        [3.6785e-03],\n","        [2.4160e-03],\n","        [8.5149e-03],\n","        [7.2802e-03],\n","        [3.1832e-03],\n","        [5.1328e-03],\n","        [1.2626e-03],\n","        [5.6175e-03],\n","        [7.4359e-03],\n","        [6.6080e-03],\n","        [1.8972e-03],\n","        [4.5415e-03],\n","        [7.5261e-03],\n","        [6.6819e-03],\n","        [9.3686e-03],\n","        [9.3678e-03],\n","        [5.6835e-03],\n","        [1.7040e-03],\n","        [7.9508e-03],\n","        [8.1406e-03],\n","        [3.0941e-03],\n","        [7.5644e-03],\n","        [7.4587e-03],\n","        [1.3149e-03],\n","        [3.8895e-03],\n","        [2.8641e-03],\n","        [5.5825e-03],\n","        [2.3895e-03],\n","        [3.5343e-03],\n","        [7.2948e-03],\n","        [7.8438e-03],\n","        [8.9346e-04],\n","        [3.4920e-03],\n","        [8.4655e-03],\n","        [8.5957e-03],\n","        [3.9640e-03],\n","        [1.9857e-05],\n","        [6.0708e-03],\n","        [8.3113e-03],\n","        [9.0259e-03],\n","        [1.6266e-03],\n","        [1.3741e-03],\n","        [2.6306e-03],\n","        [6.0025e-03],\n","        [2.3597e-04],\n","        [1.6939e-03],\n","        [4.5020e-03],\n","        [4.5870e-03],\n","        [4.6820e-03],\n","        [4.0316e-03],\n","        [5.4608e-03],\n","        [2.0226e-03],\n","        [8.4080e-03],\n","        [8.4062e-03],\n","        [2.2259e-03],\n","        [7.2899e-03],\n","        [5.9691e-03],\n","        [8.7318e-03],\n","        [3.9709e-03],\n","        [6.4037e-03],\n","        [5.0106e-03],\n","        [3.3210e-03],\n","        [8.8398e-03],\n","        [1.1628e-03],\n","        [1.4018e-04],\n","        [6.7419e-03],\n","        [6.2346e-03],\n","        [6.4588e-03],\n","        [6.8005e-03],\n","        [7.2138e-03],\n","        [7.2217e-03],\n","        [1.3160e-03],\n","        [7.4927e-03],\n","        [8.0705e-03],\n","        [2.5520e-03],\n","        [6.1733e-03],\n","        [8.4148e-03],\n","        [6.8184e-03],\n","        [5.2352e-03],\n","        [2.4425e-03],\n","        [9.1327e-03],\n","        [8.1743e-03],\n","        [6.9133e-03],\n","        [1.9904e-03],\n","        [6.7804e-03],\n","        [6.3000e-03],\n","        [2.3593e-03],\n","        [4.1635e-03],\n","        [2.9885e-04],\n","        [9.2221e-03],\n","        [5.2018e-03],\n","        [7.6305e-03],\n","        [4.4355e-03],\n","        [5.4922e-03],\n","        [7.3290e-03],\n","        [8.1384e-03],\n","        [4.8371e-03],\n","        [1.4123e-03],\n","        [1.8921e-03],\n","        [6.1608e-03],\n","        [4.3759e-03],\n","        [4.9801e-03],\n","        [9.1514e-03],\n","        [1.1688e-03],\n","        [8.6735e-03],\n","        [3.9166e-03],\n","        [4.7575e-03],\n","        [2.4471e-03],\n","        [3.5511e-03],\n","        [6.5328e-03],\n","        [1.6027e-03],\n","        [9.2769e-03],\n","        [6.1159e-03],\n","        [8.3130e-03],\n","        [3.4551e-03],\n","        [8.8495e-03],\n","        [5.6870e-03],\n","        [4.6102e-03],\n","        [7.0284e-03],\n","        [1.0693e-03],\n","        [2.7279e-03],\n","        [1.8035e-03],\n","        [2.5701e-03]])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fGg4lxlcX9PS","executionInfo":{"status":"ok","timestamp":1628549039239,"user_tz":-60,"elapsed":412,"user":{"displayName":"Akshay Parmar","photoUrl":"","userId":"04463184220884570036"}},"outputId":"735448b4-1d80-4a43-e2d0-9923cc336631"},"source":["# volatility \n","\n","a,b = 500 ,1 #dimension of the pytorch tensor to be generated\n","low , high =  0.01, 0.5 #range of uniform distribution [1%,50%]\n","torch.manual_seed(30) #Fx the values\n","si = torch.distributions.uniform.Uniform(low, high).sample([a,b]) # samples from low and high values. a,b are the dimensions\n","# whenevr we want to fix a distribution we just use torch.manual_seed to fix the distribution.\n","Sigma = si.view(500,1)\n","print(Sigma) # 500 samples by 1 column"],"execution_count":8,"outputs":[{"output_type":"stream","text":["tensor([[0.4514],\n","        [0.3757],\n","        [0.2411],\n","        [0.4381],\n","        [0.3727],\n","        [0.3942],\n","        [0.4483],\n","        [0.3157],\n","        [0.2195],\n","        [0.4226],\n","        [0.3753],\n","        [0.3129],\n","        [0.4452],\n","        [0.2122],\n","        [0.0957],\n","        [0.1779],\n","        [0.4695],\n","        [0.0302],\n","        [0.0652],\n","        [0.3516],\n","        [0.4392],\n","        [0.1650],\n","        [0.1565],\n","        [0.3935],\n","        [0.3300],\n","        [0.2168],\n","        [0.1643],\n","        [0.2949],\n","        [0.0422],\n","        [0.1794],\n","        [0.4824],\n","        [0.1320],\n","        [0.0675],\n","        [0.3004],\n","        [0.2617],\n","        [0.2919],\n","        [0.1110],\n","        [0.1941],\n","        [0.0984],\n","        [0.2388],\n","        [0.0343],\n","        [0.2921],\n","        [0.0825],\n","        [0.1794],\n","        [0.1159],\n","        [0.1430],\n","        [0.4850],\n","        [0.4166],\n","        [0.0313],\n","        [0.2637],\n","        [0.1704],\n","        [0.2162],\n","        [0.1260],\n","        [0.1823],\n","        [0.1882],\n","        [0.2323],\n","        [0.4098],\n","        [0.4110],\n","        [0.2561],\n","        [0.0781],\n","        [0.3467],\n","        [0.1347],\n","        [0.4749],\n","        [0.2663],\n","        [0.4695],\n","        [0.0810],\n","        [0.4652],\n","        [0.0675],\n","        [0.4289],\n","        [0.3207],\n","        [0.2545],\n","        [0.2627],\n","        [0.4128],\n","        [0.1448],\n","        [0.2218],\n","        [0.4398],\n","        [0.4658],\n","        [0.3817],\n","        [0.3237],\n","        [0.4903],\n","        [0.3417],\n","        [0.3773],\n","        [0.3409],\n","        [0.3452],\n","        [0.1534],\n","        [0.2437],\n","        [0.2193],\n","        [0.1330],\n","        [0.3613],\n","        [0.0485],\n","        [0.3582],\n","        [0.3870],\n","        [0.4234],\n","        [0.2791],\n","        [0.3323],\n","        [0.2974],\n","        [0.3894],\n","        [0.0725],\n","        [0.1000],\n","        [0.2808],\n","        [0.4370],\n","        [0.4105],\n","        [0.4037],\n","        [0.4038],\n","        [0.4402],\n","        [0.4757],\n","        [0.2445],\n","        [0.1365],\n","        [0.3571],\n","        [0.4800],\n","        [0.1824],\n","        [0.4477],\n","        [0.2060],\n","        [0.0366],\n","        [0.2494],\n","        [0.1351],\n","        [0.1299],\n","        [0.3772],\n","        [0.3144],\n","        [0.3131],\n","        [0.3775],\n","        [0.0983],\n","        [0.2545],\n","        [0.2297],\n","        [0.1275],\n","        [0.3867],\n","        [0.2106],\n","        [0.0500],\n","        [0.4216],\n","        [0.3850],\n","        [0.1226],\n","        [0.3378],\n","        [0.4768],\n","        [0.1791],\n","        [0.3353],\n","        [0.1584],\n","        [0.4796],\n","        [0.2996],\n","        [0.3502],\n","        [0.0724],\n","        [0.1490],\n","        [0.0476],\n","        [0.1120],\n","        [0.4510],\n","        [0.1701],\n","        [0.1527],\n","        [0.3847],\n","        [0.4342],\n","        [0.4463],\n","        [0.3818],\n","        [0.2177],\n","        [0.2201],\n","        [0.3777],\n","        [0.4505],\n","        [0.3170],\n","        [0.0834],\n","        [0.1341],\n","        [0.2871],\n","        [0.2142],\n","        [0.3664],\n","        [0.2620],\n","        [0.1639],\n","        [0.2722],\n","        [0.1486],\n","        [0.1033],\n","        [0.1105],\n","        [0.1249],\n","        [0.4994],\n","        [0.2149],\n","        [0.1513],\n","        [0.2327],\n","        [0.2158],\n","        [0.2059],\n","        [0.1668],\n","        [0.1734],\n","        [0.0600],\n","        [0.2658],\n","        [0.0307],\n","        [0.1379],\n","        [0.4661],\n","        [0.1875],\n","        [0.0569],\n","        [0.1537],\n","        [0.3013],\n","        [0.4840],\n","        [0.2221],\n","        [0.2095],\n","        [0.3012],\n","        [0.3120],\n","        [0.0776],\n","        [0.0588],\n","        [0.0382],\n","        [0.1720],\n","        [0.1364],\n","        [0.0211],\n","        [0.3436],\n","        [0.4875],\n","        [0.2320],\n","        [0.2742],\n","        [0.1811],\n","        [0.2891],\n","        [0.1360],\n","        [0.2758],\n","        [0.0996],\n","        [0.4042],\n","        [0.0511],\n","        [0.3039],\n","        [0.3252],\n","        [0.4755],\n","        [0.4783],\n","        [0.0382],\n","        [0.0754],\n","        [0.4075],\n","        [0.4081],\n","        [0.2029],\n","        [0.0967],\n","        [0.4788],\n","        [0.3748],\n","        [0.0234],\n","        [0.3609],\n","        [0.3737],\n","        [0.4136],\n","        [0.1079],\n","        [0.3032],\n","        [0.2389],\n","        [0.0380],\n","        [0.3466],\n","        [0.2889],\n","        [0.0223],\n","        [0.4493],\n","        [0.4873],\n","        [0.2818],\n","        [0.4851],\n","        [0.4406],\n","        [0.3767],\n","        [0.0210],\n","        [0.4878],\n","        [0.2608],\n","        [0.2984],\n","        [0.4238],\n","        [0.3766],\n","        [0.1922],\n","        [0.0199],\n","        [0.1106],\n","        [0.0981],\n","        [0.3861],\n","        [0.2840],\n","        [0.3211],\n","        [0.1657],\n","        [0.1768],\n","        [0.1150],\n","        [0.2666],\n","        [0.1904],\n","        [0.0397],\n","        [0.2065],\n","        [0.0180],\n","        [0.0573],\n","        [0.1098],\n","        [0.3864],\n","        [0.3301],\n","        [0.1655],\n","        [0.2990],\n","        [0.2668],\n","        [0.3966],\n","        [0.3897],\n","        [0.2258],\n","        [0.4724],\n","        [0.2284],\n","        [0.2900],\n","        [0.2423],\n","        [0.3868],\n","        [0.1910],\n","        [0.4313],\n","        [0.4511],\n","        [0.4943],\n","        [0.4486],\n","        [0.1539],\n","        [0.0370],\n","        [0.2381],\n","        [0.2066],\n","        [0.1282],\n","        [0.0954],\n","        [0.1868],\n","        [0.1222],\n","        [0.0537],\n","        [0.3309],\n","        [0.3321],\n","        [0.4771],\n","        [0.4894],\n","        [0.0162],\n","        [0.3052],\n","        [0.4868],\n","        [0.4560],\n","        [0.0232],\n","        [0.4770],\n","        [0.3245],\n","        [0.2194],\n","        [0.2071],\n","        [0.3608],\n","        [0.1502],\n","        [0.0577],\n","        [0.0643],\n","        [0.3298],\n","        [0.4225],\n","        [0.1324],\n","        [0.2380],\n","        [0.2301],\n","        [0.4547],\n","        [0.2385],\n","        [0.1050],\n","        [0.2420],\n","        [0.2405],\n","        [0.2301],\n","        [0.0953],\n","        [0.4756],\n","        [0.3905],\n","        [0.3200],\n","        [0.1249],\n","        [0.3356],\n","        [0.1937],\n","        [0.3010],\n","        [0.0791],\n","        [0.4800],\n","        [0.3325],\n","        [0.1232],\n","        [0.2940],\n","        [0.3072],\n","        [0.2847],\n","        [0.1840],\n","        [0.1715],\n","        [0.4908],\n","        [0.1716],\n","        [0.4823],\n","        [0.1621],\n","        [0.0289],\n","        [0.3950],\n","        [0.0553],\n","        [0.0792],\n","        [0.4489],\n","        [0.4930],\n","        [0.3430],\n","        [0.4128],\n","        [0.4779],\n","        [0.3431],\n","        [0.2605],\n","        [0.2681],\n","        [0.3659],\n","        [0.3504],\n","        [0.2351],\n","        [0.4055],\n","        [0.1290],\n","        [0.3247],\n","        [0.4861],\n","        [0.0241],\n","        [0.0475],\n","        [0.2643],\n","        [0.2280],\n","        [0.1962],\n","        [0.2527],\n","        [0.3038],\n","        [0.2147],\n","        [0.3503],\n","        [0.2016],\n","        [0.3750],\n","        [0.2856],\n","        [0.3865],\n","        [0.2009],\n","        [0.4044],\n","        [0.0611],\n","        [0.3139],\n","        [0.0160],\n","        [0.2178],\n","        [0.1030],\n","        [0.0628],\n","        [0.1347],\n","        [0.3637],\n","        [0.1304],\n","        [0.3124],\n","        [0.2332],\n","        [0.3612],\n","        [0.0502],\n","        [0.2526],\n","        [0.0913],\n","        [0.1230],\n","        [0.1814],\n","        [0.4366],\n","        [0.0167],\n","        [0.2709],\n","        [0.0273],\n","        [0.2689],\n","        [0.0174],\n","        [0.4551],\n","        [0.0714],\n","        [0.3105],\n","        [0.1500],\n","        [0.3334],\n","        [0.3277],\n","        [0.0998],\n","        [0.1143],\n","        [0.2409],\n","        [0.4020],\n","        [0.4942],\n","        [0.1752],\n","        [0.3539],\n","        [0.1475],\n","        [0.0977],\n","        [0.4140],\n","        [0.1110],\n","        [0.4274],\n","        [0.2888],\n","        [0.0519],\n","        [0.3019],\n","        [0.2090],\n","        [0.1231],\n","        [0.0174],\n","        [0.2936],\n","        [0.0393],\n","        [0.4037],\n","        [0.3912],\n","        [0.1453],\n","        [0.4318],\n","        [0.1670],\n","        [0.0659],\n","        [0.2492],\n","        [0.3730],\n","        [0.1423],\n","        [0.3575],\n","        [0.3084],\n","        [0.1660],\n","        [0.2246],\n","        [0.3237],\n","        [0.1751],\n","        [0.0364],\n","        [0.3551],\n","        [0.3833],\n","        [0.1141],\n","        [0.0914],\n","        [0.1116],\n","        [0.4475],\n","        [0.0462],\n","        [0.3775],\n","        [0.3229],\n","        [0.2980],\n","        [0.1301],\n","        [0.0632],\n","        [0.0313],\n","        [0.0877],\n","        [0.0867],\n","        [0.1798],\n","        [0.1251],\n","        [0.2049],\n","        [0.2178],\n","        [0.4660],\n","        [0.0655],\n","        [0.4221],\n","        [0.0650],\n","        [0.2277],\n","        [0.3825],\n","        [0.1430],\n","        [0.1047],\n","        [0.3004],\n","        [0.2258],\n","        [0.3615],\n","        [0.1670],\n","        [0.4317],\n","        [0.2063],\n","        [0.0192],\n","        [0.4166],\n","        [0.4669],\n","        [0.4139],\n","        [0.2352],\n","        [0.1498],\n","        [0.0953],\n","        [0.0908],\n","        [0.1015],\n","        [0.3043],\n","        [0.2694],\n","        [0.1313],\n","        [0.2167],\n","        [0.3122],\n","        [0.4246],\n","        [0.4496],\n","        [0.4540],\n","        [0.3288],\n","        [0.0663],\n","        [0.3741],\n","        [0.1717],\n","        [0.3613],\n","        [0.1061],\n","        [0.3046],\n","        [0.0804],\n","        [0.0979],\n","        [0.0169],\n","        [0.1593],\n","        [0.3960],\n","        [0.0487],\n","        [0.2548],\n","        [0.4566],\n","        [0.2504],\n","        [0.3334]])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4zAKw8yQkcuc","executionInfo":{"status":"ok","timestamp":1628549055170,"user_tz":-60,"elapsed":691,"user":{"displayName":"Akshay Parmar","photoUrl":"","userId":"04463184220884570036"}},"outputId":"5a1b3500-19f5-469f-b5ba-f4e01d98fddf"},"source":["# Stock, Time, Rate ,Sigma -> 4 features (variables)\n","# Strike\n","# https://discuss.pytorch.org/t/tensor-stack-or-concatenate/34331/6 - column and concatinate \n","\n","X = torch.column_stack([Stock, Time, Rate, Sigma])\n","print(X)\n","print(X.shape) # m x n matrix \n"],"execution_count":9,"outputs":[{"output_type":"stream","text":["tensor([[1.1180e+02, 7.0959e-01, 4.6569e-03, 4.5136e-01],\n","        [5.6869e+01, 1.8685e+00, 2.3277e-03, 3.7572e-01],\n","        [8.8928e+01, 1.3342e+00, 4.5272e-03, 2.4109e-01],\n","        ...,\n","        [5.9128e+01, 1.7836e+00, 2.7279e-03, 4.5660e-01],\n","        [9.8155e+01, 7.0685e-01, 1.8035e-03, 2.5040e-01],\n","        [1.0653e+02, 1.7068e+00, 2.5701e-03, 3.3336e-01]])\n","torch.Size([500, 4])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"5D2rrSYamJ8K","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628549060566,"user_tz":-60,"elapsed":336,"user":{"displayName":"Akshay Parmar","photoUrl":"","userId":"04463184220884570036"}},"outputId":"e2e67045-f97d-4889-aad6-20495ca60a0c"},"source":["X.requires_grad_(True) # graident for backprop activated with requires_grad true\n","X.retain_grad() # leaf tensor is a root of the tree \n","\n","print(X.shape) "],"execution_count":10,"outputs":[{"output_type":"stream","text":["torch.Size([500, 4])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ESFMMccbtMqB","executionInfo":{"status":"ok","timestamp":1628549063207,"user_tz":-60,"elapsed":8,"user":{"displayName":"Akshay Parmar","photoUrl":"","userId":"04463184220884570036"}}},"source":["# non- divident paying asset. \n","# P + S - C = K * e^-r(T-t)\n","# Set strike price = 100\n","\n","Strike = 100 # fixed hyper paramters. \n","\n","# Our case this is a fixed paramter. "],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"ucjoPZ3CyyWU","executionInfo":{"status":"ok","timestamp":1628549067320,"user_tz":-60,"elapsed":380,"user":{"displayName":"Akshay Parmar","photoUrl":"","userId":"04463184220884570036"}}},"source":["def euro_vanilla_call(x):\n","  d1 = (torch.log(x[0] / Strike) + (x[2] + 0.5 * x[3] ** 2) * x[1]) / (x[3] * torch.sqrt(x[1]))\n","  d2 = (torch.log(x[0] / Strike) + (x[2] - 0.5 * x[3] ** 2) * x[1]) / (x[3] * torch.sqrt(x[1]))\n","    \n","  call = (x[0] * torch.distributions.normal.Normal(0,1).cdf(d1) - Strike * torch.exp(-x[2] * x[1]) * torch.distributions.normal.Normal(0,1).cdf(d2))\n","\n","  return call\n","# https://pytorch.org/docs/stable/distributions.html - Normal( loc,scale)\n","#https://www.itl.nist.gov/div898/handbook/eda/section3/eda364.htm - loc and scale the same as mean and standard deviation.\n","# https://pytorch.org/docs/stable/generated/torch.log.html - returns natrual logarithem\n","# https://pytorch.org/docs/stable/generated/torch.sqrt.html - returns squart root\n"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"B08tU-Ph1DEn","executionInfo":{"status":"ok","timestamp":1628549070935,"user_tz":-60,"elapsed":472,"user":{"displayName":"Akshay Parmar","photoUrl":"","userId":"04463184220884570036"}},"outputId":"3980fd83-e100-439f-8055-cb962ef19889"},"source":["y = torch.zeros(size = (500 , 1)) # samples\n","\n","for i in range(X.shape[0]):\n","  y[i] = euro_vanilla_call(X[i]) # runs through each row computation. \n","\n","print(y) # M samples dimension all in all. "],"execution_count":13,"outputs":[{"output_type":"stream","text":["tensor([[ 2.2721e+01],\n","        [ 2.6445e+00],\n","        [ 6.0082e+00],\n","        [ 1.1345e+00],\n","        [ 1.3856e+01],\n","        [ 4.1641e+00],\n","        [ 1.2586e+01],\n","        [ 6.4811e+00],\n","        [ 1.7054e+01],\n","        [ 4.9546e+01],\n","        [ 5.2213e-01],\n","        [ 1.2441e+01],\n","        [ 2.4887e+01],\n","        [ 5.0325e+01],\n","        [ 1.1689e+01],\n","        [ 9.2247e+00],\n","        [ 3.5610e+01],\n","        [ 0.0000e+00],\n","        [ 1.4142e-05],\n","        [ 1.5222e+01],\n","        [ 3.1163e+01],\n","        [ 9.1199e+00],\n","        [ 0.0000e+00],\n","        [ 5.0606e+00],\n","        [ 6.1015e-01],\n","        [ 2.5259e+00],\n","        [ 3.0119e-04],\n","        [ 2.3009e+01],\n","        [ 2.5393e+01],\n","        [ 3.3681e-02],\n","        [ 1.7437e+01],\n","        [ 3.5364e-02],\n","        [ 4.3309e-03],\n","        [ 5.5197e+00],\n","        [ 8.1241e+00],\n","        [ 3.1608e+01],\n","        [ 1.9335e+01],\n","        [ 2.7152e+01],\n","        [ 7.7752e-04],\n","        [ 3.7977e+01],\n","        [ 3.5301e+01],\n","        [ 1.7973e-02],\n","        [ 1.8367e-05],\n","        [ 8.9325e-01],\n","        [ 9.8600e+00],\n","        [-1.3684e-06],\n","        [ 0.0000e+00],\n","        [ 3.2383e+01],\n","        [ 0.0000e+00],\n","        [ 2.6717e+01],\n","        [ 3.9580e+00],\n","        [ 3.7449e+01],\n","        [ 2.4446e+01],\n","        [ 4.7299e+01],\n","        [ 8.0716e+00],\n","        [ 2.6576e+00],\n","        [ 1.6423e-02],\n","        [ 1.1538e+01],\n","        [ 2.8452e-01],\n","        [ 0.0000e+00],\n","        [ 1.1676e+00],\n","        [ 4.7218e+00],\n","        [ 3.4604e+01],\n","        [ 4.3360e+01],\n","        [ 1.2991e+01],\n","        [ 5.0267e+00],\n","        [ 0.0000e+00],\n","        [ 2.7286e+00],\n","        [ 7.9617e+00],\n","        [ 6.4969e+00],\n","        [ 6.9146e-06],\n","        [ 1.9393e+01],\n","        [ 5.1186e+01],\n","        [ 3.2869e+01],\n","        [ 5.6599e+00],\n","        [ 2.9384e+01],\n","        [ 1.0092e+01],\n","        [ 3.5667e+01],\n","        [ 3.7519e+01],\n","        [ 1.7651e+00],\n","        [ 3.1294e+01],\n","        [ 6.5131e-02],\n","        [ 3.5743e+01],\n","        [ 3.7164e+01],\n","        [ 4.6496e+01],\n","        [ 1.6375e+01],\n","        [ 1.8229e+01],\n","        [ 2.3730e+01],\n","        [ 5.1924e+01],\n","        [ 4.6979e+01],\n","        [ 4.0193e+00],\n","        [ 4.8789e+01],\n","        [ 4.3932e+01],\n","        [ 1.1861e+01],\n","        [ 5.0110e+01],\n","        [ 5.9530e-01],\n","        [ 2.3510e+01],\n","        [ 0.0000e+00],\n","        [ 1.0085e-05],\n","        [ 5.0497e+01],\n","        [ 4.2984e+00],\n","        [ 9.2994e+00],\n","        [ 4.8631e+01],\n","        [ 5.1178e+00],\n","        [ 2.7095e+01],\n","        [ 8.2654e-01],\n","        [ 5.5484e-01],\n","        [ 2.4360e-05],\n","        [ 3.0788e+01],\n","        [ 2.0376e+01],\n","        [ 2.5944e+01],\n","        [ 2.6889e+01],\n","        [ 9.8271e-03],\n","        [ 3.1399e+01],\n","        [ 4.3841e+01],\n","        [ 4.4609e+01],\n","        [ 1.5876e+01],\n","        [ 9.5195e+00],\n","        [ 3.6845e+01],\n","        [ 1.7797e+01],\n","        [ 1.6826e+01],\n","        [ 2.4287e+00],\n","        [ 3.1320e+01],\n","        [ 2.0043e+01],\n","        [ 1.2947e-01],\n","        [ 4.4045e+01],\n","        [ 2.4800e+00],\n","        [ 4.6169e+01],\n","        [ 9.5953e+00],\n","        [ 4.5866e+00],\n","        [ 4.2276e+00],\n","        [ 3.7272e+01],\n","        [ 3.9069e+01],\n","        [ 8.2948e+00],\n","        [ 5.1220e-01],\n","        [ 5.9767e-01],\n","        [ 1.0196e+01],\n","        [ 7.0816e-01],\n","        [ 1.9749e+01],\n","        [ 2.5807e+00],\n","        [ 2.5530e+01],\n","        [ 1.8545e+01],\n","        [ 3.5915e+01],\n","        [ 1.9321e+01],\n","        [ 2.1892e-02],\n","        [ 2.5084e+00],\n","        [ 8.6649e+00],\n","        [ 2.4384e+01],\n","        [ 7.9638e+00],\n","        [ 4.3121e+01],\n","        [ 3.1272e+01],\n","        [ 3.2924e+01],\n","        [ 1.8447e+01],\n","        [ 2.0682e+00],\n","        [ 4.8064e+01],\n","        [ 1.1942e+00],\n","        [ 2.0201e-01],\n","        [ 3.1990e+01],\n","        [ 4.3830e+01],\n","        [ 1.2262e-02],\n","        [ 1.3450e+01],\n","        [ 2.8783e+01],\n","        [ 3.2658e+01],\n","        [ 0.0000e+00],\n","        [ 1.6279e-06],\n","        [ 2.1296e+01],\n","        [ 1.3790e-01],\n","        [ 1.0744e+01],\n","        [ 1.1187e+00],\n","        [ 1.1436e+01],\n","        [ 6.0830e+00],\n","        [ 2.2974e+01],\n","        [ 3.1641e+01],\n","        [ 7.0282e-04],\n","        [-3.3572e-07],\n","        [ 2.5611e-03],\n","        [ 3.2413e+01],\n","        [-6.1244e-07],\n","        [ 1.5972e+01],\n","        [ 3.6554e+01],\n","        [ 1.3295e+00],\n","        [ 8.7442e-04],\n","        [ 4.9102e+01],\n","        [ 4.1757e-01],\n","        [ 7.2757e+00],\n","        [ 3.4677e-05],\n","        [ 7.4413e-01],\n","        [ 1.9261e-01],\n","        [ 5.1981e+01],\n","        [ 2.9339e-05],\n","        [ 3.7810e+01],\n","        [ 4.9609e-01],\n","        [ 1.3254e+01],\n","        [ 1.0997e+01],\n","        [ 4.7507e+01],\n","        [ 4.9055e+01],\n","        [ 4.2746e+01],\n","        [ 3.6284e+01],\n","        [ 3.5700e+00],\n","        [ 2.2425e+01],\n","        [ 2.4099e+01],\n","        [ 2.5489e+01],\n","        [ 7.7592e+00],\n","        [ 4.0422e-03],\n","        [ 1.2029e+01],\n","        [ 4.6937e+01],\n","        [ 2.3034e+01],\n","        [ 1.9545e+01],\n","        [ 4.1824e-03],\n","        [ 3.4041e+01],\n","        [ 0.0000e+00],\n","        [ 7.4964e-01],\n","        [ 3.3430e+01],\n","        [ 1.2046e+00],\n","        [ 5.9525e+00],\n","        [ 3.5006e+01],\n","        [ 8.4488e+00],\n","        [ 8.3175e+00],\n","        [ 0.0000e+00],\n","        [ 9.2232e+00],\n","        [ 5.0491e+01],\n","        [ 1.4508e+01],\n","        [ 3.0053e+01],\n","        [ 1.7991e+01],\n","        [ 7.4437e+00],\n","        [ 1.7420e+01],\n","        [ 2.0577e+01],\n","        [ 5.3489e+00],\n","        [ 1.2179e+01],\n","        [ 2.1829e+01],\n","        [ 6.2160e+01],\n","        [ 3.3498e+01],\n","        [ 5.7522e+00],\n","        [ 8.8790e+00],\n","        [ 1.6754e+00],\n","        [ 2.3712e+01],\n","        [ 4.3164e+01],\n","        [ 2.1128e-01],\n","        [ 1.4714e+01],\n","        [ 7.7010e+00],\n","        [ 2.4940e+01],\n","        [ 7.8247e+00],\n","        [ 0.0000e+00],\n","        [ 1.2937e+00],\n","        [ 2.2736e+01],\n","        [ 2.3109e+01],\n","        [ 2.8592e+01],\n","        [ 6.3280e+00],\n","        [ 1.4324e+01],\n","        [ 3.0993e+00],\n","        [ 3.9515e+01],\n","        [ 4.2390e+01],\n","        [ 1.5172e+01],\n","        [ 2.7623e+00],\n","        [ 1.5693e+00],\n","        [ 0.0000e+00],\n","        [ 4.2565e+01],\n","        [ 8.1841e+00],\n","        [ 3.4467e+00],\n","        [ 6.3089e-04],\n","        [ 0.0000e+00],\n","        [ 9.0134e+00],\n","        [ 1.6660e+01],\n","        [ 8.1734e+00],\n","        [ 1.1644e+01],\n","        [ 9.0140e+00],\n","        [ 3.5914e+01],\n","        [ 2.8346e+01],\n","        [ 5.1452e+00],\n","        [ 1.2161e+01],\n","        [ 1.0118e+01],\n","        [ 3.3898e+01],\n","        [ 5.9361e-05],\n","        [ 9.2695e-01],\n","        [ 1.0417e+01],\n","        [ 1.4048e+01],\n","        [ 1.5538e+01],\n","        [ 0.0000e+00],\n","        [ 3.6627e+01],\n","        [ 3.3450e+01],\n","        [ 4.8163e+01],\n","        [ 2.3531e-03],\n","        [ 2.8289e-01],\n","        [ 1.0045e+01],\n","        [ 0.0000e+00],\n","        [ 4.3800e+01],\n","        [ 5.8888e+00],\n","        [ 1.0413e+01],\n","        [ 2.1901e+01],\n","        [ 0.0000e+00],\n","        [ 1.1695e+01],\n","        [ 5.5176e+01],\n","        [ 0.0000e+00],\n","        [ 5.3176e+00],\n","        [ 4.5960e+01],\n","        [ 9.1607e+00],\n","        [ 1.7525e+01],\n","        [ 1.8219e+01],\n","        [ 7.5777e-03],\n","        [-1.3499e-06],\n","        [ 3.0987e+01],\n","        [ 0.0000e+00],\n","        [ 1.6827e+01],\n","        [ 5.2700e+01],\n","        [ 2.2262e-01],\n","        [ 1.2232e+01],\n","        [ 1.0349e+00],\n","        [ 3.0364e+00],\n","        [ 2.1759e+01],\n","        [ 2.2554e-06],\n","        [ 3.4640e-02],\n","        [ 1.6791e+01],\n","        [ 3.6794e+01],\n","        [ 2.4592e+01],\n","        [ 3.1258e+01],\n","        [ 1.2197e+01],\n","        [ 1.0943e+01],\n","        [ 4.9974e+01],\n","        [ 2.1283e+01],\n","        [ 1.2509e+01],\n","        [ 4.6826e+01],\n","        [ 3.8232e+01],\n","        [ 3.5780e+01],\n","        [ 2.4925e+01],\n","        [ 1.0665e+01],\n","        [ 1.8474e+01],\n","        [ 4.8183e+01],\n","        [ 6.0387e-01],\n","        [ 1.1854e+01],\n","        [ 2.0480e+01],\n","        [ 2.3143e+01],\n","        [ 1.5398e+01],\n","        [ 5.3534e+01],\n","        [ 4.1377e+01],\n","        [ 4.3675e+01],\n","        [ 1.2336e-01],\n","        [ 0.0000e+00],\n","        [ 6.1783e+00],\n","        [ 1.9556e+01],\n","        [ 4.4036e+01],\n","        [ 3.0358e+01],\n","        [ 3.2269e-01],\n","        [ 5.4659e-01],\n","        [ 1.4032e+00],\n","        [ 5.0398e+01],\n","        [ 2.4596e-03],\n","        [ 4.6948e+00],\n","        [ 1.7470e+01],\n","        [ 2.7893e+01],\n","        [ 3.1299e+01],\n","        [ 1.7995e+00],\n","        [ 4.4331e+01],\n","        [ 1.1868e-01],\n","        [ 1.7670e+01],\n","        [ 0.0000e+00],\n","        [ 5.5270e-01],\n","        [ 4.5339e+01],\n","        [ 6.3822e-01],\n","        [ 1.2851e+01],\n","        [ 3.2148e+01],\n","        [ 1.8068e-04],\n","        [ 3.9987e+01],\n","        [ 3.9825e-03],\n","        [ 4.7978e-02],\n","        [ 2.4396e+01],\n","        [ 2.3826e+01],\n","        [ 1.4376e+01],\n","        [ 4.4042e+01],\n","        [ 1.9967e+01],\n","        [ 1.4511e+01],\n","        [ 0.0000e+00],\n","        [ 1.3337e+00],\n","        [ 1.3013e-01],\n","        [ 2.3094e+01],\n","        [ 1.3534e+01],\n","        [ 4.7756e+01],\n","        [ 2.7109e+00],\n","        [ 3.3304e+01],\n","        [ 2.0391e+01],\n","        [ 5.0988e+01],\n","        [ 2.5135e+00],\n","        [ 1.3313e+01],\n","        [ 7.2661e-05],\n","        [-1.1165e-06],\n","        [ 2.4168e+01],\n","        [ 3.0532e+01],\n","        [ 4.4829e+01],\n","        [ 4.7819e+01],\n","        [ 2.0775e+01],\n","        [ 1.6895e+01],\n","        [ 3.5908e+01],\n","        [ 1.4107e+00],\n","        [ 9.7128e-02],\n","        [ 1.6675e+01],\n","        [ 5.8705e+00],\n","        [ 1.2408e+01],\n","        [ 4.2866e+01],\n","        [ 3.0731e-02],\n","        [ 1.7769e-07],\n","        [ 1.5985e+01],\n","        [ 1.5861e+01],\n","        [ 1.7658e+01],\n","        [ 8.2031e+00],\n","        [ 1.9120e-01],\n","        [ 7.5862e-01],\n","        [ 1.7768e+01],\n","        [ 4.3007e+00],\n","        [ 1.3561e+01],\n","        [ 2.2036e+01],\n","        [ 4.6856e+01],\n","        [ 7.7122e-05],\n","        [ 4.0206e+01],\n","        [ 7.3109e-02],\n","        [ 4.2405e+01],\n","        [ 3.3022e+01],\n","        [ 6.9507e-01],\n","        [ 3.4226e+01],\n","        [ 1.3421e+01],\n","        [ 2.3472e+01],\n","        [ 1.6251e-05],\n","        [ 6.5708e+00],\n","        [ 2.1347e+00],\n","        [ 1.7303e-01],\n","        [ 5.1154e-01],\n","        [ 6.0922e+00],\n","        [ 1.4708e+01],\n","        [ 2.1073e+01],\n","        [ 3.3681e+01],\n","        [ 1.7580e+00],\n","        [ 4.6328e+01],\n","        [ 8.7856e+00],\n","        [ 2.1263e+01],\n","        [ 1.5606e-05],\n","        [ 2.0166e-01],\n","        [ 2.1512e+00],\n","        [ 4.3429e-04],\n","        [ 3.3147e+00],\n","        [ 2.7331e+01],\n","        [ 9.4446e-01],\n","        [ 1.5938e+00],\n","        [ 3.5172e+01],\n","        [ 4.1986e+01],\n","        [ 2.2096e+01],\n","        [ 0.0000e+00],\n","        [ 3.4161e-01],\n","        [ 4.6611e+01],\n","        [ 3.8201e+01],\n","        [ 4.6872e+01],\n","        [ 1.1079e+01],\n","        [ 1.0527e+00],\n","        [ 3.0204e-06],\n","        [ 3.5664e+01],\n","        [ 6.9053e+00],\n","        [ 2.0267e+01],\n","        [ 3.5379e+01],\n","        [ 3.6439e+01],\n","        [ 0.0000e+00],\n","        [ 3.9690e+01],\n","        [ 5.1341e+01],\n","        [ 0.0000e+00],\n","        [ 3.2024e+00],\n","        [ 4.8424e+01],\n","        [ 3.0179e+01],\n","        [-1.3841e-06],\n","        [ 2.8658e+01],\n","        [ 2.0067e+01],\n","        [ 0.0000e+00],\n","        [ 2.7245e+01],\n","        [ 2.4530e-01],\n","        [ 1.3284e+01],\n","        [ 2.8928e+01],\n","        [ 1.1700e+00],\n","        [ 4.3355e+00],\n","        [-9.7463e-07],\n","        [ 2.3143e+01],\n","        [ 4.6498e+01],\n","        [ 8.8147e+00],\n","        [ 2.4162e+01],\n","        [ 2.1188e+01],\n","        [ 4.7860e+00],\n","        [ 3.8794e+00],\n","        [ 2.0222e-01],\n","        [ 1.0712e+01],\n","        [ 5.3214e+01],\n","        [ 2.3469e+01],\n","        [ 3.5745e+00],\n","        [ 4.9030e+00],\n","        [ 1.0778e+01],\n","        [ 3.7895e+01],\n","        [ 5.7857e-06],\n","        [ 1.7030e-02],\n","        [ 4.6471e+01],\n","        [ 0.0000e+00],\n","        [ 4.4354e-06],\n","        [ 1.1529e-01],\n","        [ 4.5462e+01],\n","        [ 3.6899e+01],\n","        [ 4.9687e+00],\n","        [ 7.4698e+00],\n","        [ 2.1457e+01]], grad_fn=<CopySlices>)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iPqiTLtD0_jt","executionInfo":{"status":"ok","timestamp":1628549073576,"user_tz":-60,"elapsed":452,"user":{"displayName":"Akshay Parmar","photoUrl":"","userId":"04463184220884570036"}},"outputId":"2e4a4b38-0686-4c73-b107-6a0e4e86de19"},"source":["f_o = torch.zeros(size = (500,4))\n","\n","# First order DY/DX\n","\n","for i in range(X.shape[0]):\n","  f_o[i] = torch.autograd.functional.jacobian( euro_vanilla_call, X[i])\n","\n","print(f_o.shape) # m samples by n features \n","  \n","print(f_o) # call option. Theta is always negative as depreciation with the value of the option. And measures the variation."],"execution_count":14,"outputs":[{"output_type":"stream","text":["torch.Size([500, 4])\n","tensor([[ 0.6887, 10.8391, 38.5158, 33.2855],\n","        [ 0.2022,  2.2232, 16.5465, 21.9077],\n","        [ 0.3973,  3.7116, 39.1187, 39.6127],\n","        ...,\n","        [ 0.2916,  3.5021, 21.8851, 27.0980],\n","        [ 0.5091,  5.9063, 30.0435, 32.9135],\n","        [ 0.6454,  5.1792, 80.7346, 51.7910]])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9Rd1CISh4rMr","executionInfo":{"status":"ok","timestamp":1628549078033,"user_tz":-60,"elapsed":2352,"user":{"displayName":"Akshay Parmar","photoUrl":"","userId":"04463184220884570036"}},"outputId":"94c90b1a-5868-4d1c-a130-3db521203db5"},"source":["s_o = torch.zeros(size = (500,4,4))\n","\n","#Second Order Risk D2Y/ DX2\n","\n","for i in range(X.shape[0]):\n","  s_o[i] = torch.autograd.functional.hessian(euro_vanilla_call , X[i])\n","\n","print(s_o.shape) # m samples by n features by n features .\n","  \n","print(s_o) # take logarithems if really small. Monotonic."],"execution_count":15,"outputs":[{"output_type":"stream","text":["torch.Size([500, 4, 4])\n","tensor([[[ 8.3142e-03, -2.3563e-02,  6.5959e-01, -8.7696e-02],\n","         [-2.3563e-02, -7.1748e+00,  4.4718e+01,  2.4546e+01],\n","         [ 6.5959e-01,  4.4718e+01,  2.4998e+01, -3.0576e+01],\n","         [-8.7697e-02,  2.4546e+01, -3.0576e+01,  4.0653e+00]],\n","\n","        [[ 9.6491e-03,  1.0288e-01,  1.0253e+00,  1.0106e+00],\n","         [ 1.0288e-01,  8.9427e-02,  1.5634e+01,  1.2530e+01],\n","         [ 1.0253e+00,  1.5634e+01,  7.8033e+01,  6.6451e+01],\n","         [ 1.0106e+00,  1.2530e+01,  6.6451e+01,  6.5497e+01]],\n","\n","        [[ 1.5572e-02,  8.4154e-02,  1.8476e+00,  8.6206e-01],\n","         [ 8.4154e-02, -1.1207e+00,  3.4352e+01,  1.7096e+01],\n","         [ 1.8476e+00,  3.4352e+01,  1.6703e+02,  4.9431e+01],\n","         [ 8.6206e-01,  1.7096e+01,  4.9431e+01,  2.3063e+01]],\n","\n","        ...,\n","\n","        [[ 9.5176e-03,  1.1300e-01,  1.0037e+00,  8.7078e-01],\n","         [ 1.1300e-01, -3.3685e-01,  1.7941e+01,  1.2494e+01],\n","         [ 1.0037e+00,  1.7941e+01,  6.6816e+01,  4.3500e+01],\n","         [ 8.7078e-01,  1.2494e+01,  4.3500e+01,  3.7739e+01]],\n","\n","        [[ 1.9301e-02,  5.6357e-02,  1.3392e+00,  2.9889e-01],\n","         [ 5.6357e-02, -4.1432e+00,  4.2239e+01,  2.3175e+01],\n","         [ 1.3392e+00,  4.2239e+01,  7.1676e+01, -2.5275e+00],\n","         [ 2.9889e-01,  2.3175e+01, -2.5275e+00, -5.6414e-01]],\n","\n","        [[ 8.0208e-03,  9.0090e-03,  1.4584e+00,  6.9766e-02],\n","         [ 9.0090e-03, -1.5381e+00,  4.0098e+01,  1.4704e+01],\n","         [ 1.4584e+00,  4.0098e+01,  1.2737e+02, -7.5714e+01],\n","         [ 6.9766e-02,  1.4704e+01, -7.5714e+01, -3.6220e+00]]])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"FPQPpcak471X","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628549113066,"user_tz":-60,"elapsed":377,"user":{"displayName":"Akshay Parmar","photoUrl":"","userId":"04463184220884570036"}},"outputId":"5dc8c967-61a9-42b8-ff7e-82c7b391ee66"},"source":["# Data Collection\n","\n","x = X.type(torch.FloatTensor)\n","y = y.type(torch.FloatTensor)\n","f_o = f_o.type(torch.FloatTensor)\n","s_o = s_o.type(torch.FloatTensor)\n","\n","print(X.shape)\n","print(y.shape)\n","print(f_o.shape)\n","print(s_o.shape)"],"execution_count":17,"outputs":[{"output_type":"stream","text":["torch.Size([500, 4])\n","torch.Size([500, 1])\n","torch.Size([500, 4])\n","torch.Size([500, 4, 4])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"DnVNxTEeEPsZ","executionInfo":{"status":"ok","timestamp":1628550492547,"user_tz":-60,"elapsed":812,"user":{"displayName":"Akshay Parmar","photoUrl":"","userId":"04463184220884570036"}}},"source":["# Pre-processing for pytorch. \n","\n","full_data = torch.utils.data.TensorDataset(X , y, f_o, s_o)\n","train, val = random_split(full_data, [400, 100])\n","train_loader = DataLoader(train, batch_size = 50, shuffle=False , num_workers =0) # hardcore\n","val_loader = DataLoader(val, batch_size = 50 , shuffle=False , num_workers =0)\n","\n","#X_train = train\n","#X_val, y_val, f_o_val, s_o_val = val"],"execution_count":53,"outputs":[]},{"cell_type":"code","metadata":{"id":"ON1qPjhoEP5J","executionInfo":{"status":"ok","timestamp":1628550570972,"user_tz":-60,"elapsed":335,"user":{"displayName":"Akshay Parmar","photoUrl":"","userId":"04463184220884570036"}}},"source":["# Paramters and hyperparamters \n","input_size = 4 # x features\n","hidden_size_1 = 50\n","hidden_size_2 = 30\n","output_size = 1 # y output of training \n","\n","learning_rate = 0.001 # hyperparameter\n","num_epochs = 500 # hyperparameter    \\ 250 ->  1 epoch\n","                                      # 250/32 = 6.2...    - > updating my weights every 6 training samples. \n","#    SGD, ADAM, RMSPROP AND MORE .    Wi+1 = Wi - lr* gradient L / wrt to W   goes to minimum    -> update weights\n","#                                     Bi+1 = Bi - lr* gradient L / wrt to B  goes to minimum     -> Update biases \n","alpha = 1 \n","beta = 0.5\n","delta = 0.25"],"execution_count":57,"outputs":[]},{"cell_type":"code","metadata":{"id":"n48zWC4LJvlV","executionInfo":{"status":"ok","timestamp":1628550573281,"user_tz":-60,"elapsed":469,"user":{"displayName":"Akshay Parmar","photoUrl":"","userId":"04463184220884570036"}}},"source":["class SecondOrderNetwork(pl.LightningModule):\n","  \n","  def __init__(self):\n","    super(SecondOrderNetwork,self).__init__()\n","    self.layer_1 = nn.Linear(input_size, hidden_size_1) # linear layer\n","    self.layer_2 = nn.Linear(hidden_size_1, hidden_size_2)\n","    self.layer_3 = nn.Linear(hidden_size_2, output_size)\n","\n","    self.softplus = nn.Softplus() # absolute \n","    self.loss = nn.MSELoss() # Possibility try different loss. Difference in log -> MSE(log([y]) - log([predicted_y)]) -> solves small\n","\n","    self.automatic_optimization = False # Turn off automatic optimization. Turns off backprop automatically. \n","# Automatic optimization = False does manual optimization not autoamtic - https://pytorch-lightning.readthedocs.io/en/latest/common/optimizers.html\n","  def forward(self, x):\n","    # layer 1\n","    x = self.layer_1(x)\n","    x = self.softplus(x)\n","\n","    # layer 2\n","    x = self.layer_2(x)\n","    x = self.softplus(x)\n","\n","    # layer 3 \n","    x = self.layer_3(x)\n","\n","    return x\n","\n","\n","  def training_step(self, train_batch, batch_idx):\n","    opt = self.optimizers() # access optimizers thats defined below in optimization function\n","    opt.zero_grad() # clear gradients from the preavious training set (so only keeps paramters that updated)\n","\n","    x, y, f_o, s_o = train_batch\n","    predicted_y = self.forward(x)\n","    # loop over batch\n","    predicted_f_o = torch.zeros(size=(x.shape[0], 4))\n","    for i in range(x.shape[0]): # x_shape is the batch size\n","      predicted_f_o[i] = torch.autograd.functional.jacobian(self.forward, x[i], create_graph=True, strict=True) # https://github.com/pytorch/pytorch/issues/46918 - Can show we need create_graph to be true as it backpropagets through the graph\n","\n","    predicted_s_o = torch.zeros(size=(x.shape[0], 4, 4))\n","    for i in range(x.shape[0]): # x_shape is the batch size\n","      predicted_s_o[i] = torch.autograd.functional.hessian(self.forward, x[i], create_graph=True, strict=True)\n","    # create_graph = True makes derivatives differentiable through the chain using back prop. \n","    # strict = True makes sure all inputs are connected to the outputs ortherwise an error will occur. If false it will be all zeros.\n","    loss = alpha * self.loss(y, predicted_y) + beta * self.loss( f_o, predicted_f_o) + delta * self.loss(s_o,  predicted_s_o)\n","\n","    loss.backward(retain_graph=True) # Saves gradeints and not deleted them after first backprop . \n","\n","    opt.step() # Every batch update your paramters using optimizer step. \n","\n","    self.log('train_loss', loss, on_step = False, on_epoch = True)\n","    print(loss)\n","    return loss\n","    \n","  def validation_step(self, val_batch, batch_idx):\n","    x, y, f_o, s_o = val_batch\n","    predicted_y = self.forward(x)\n","    # loop over batch\n","    predicted_f_o = torch.zeros(size=(x.shape[0], 4))\n","    for i in range(x.shape[0]): # validatio batch size\n","      predicted_f_o[i] = torch.autograd.functional.jacobian(self.forward, x[i], create_graph=True, strict=True)\n","\n","    predicted_s_o = torch.zeros(size=(x.shape[0], 4, 4))\n","    for i in range(x.shape[0]): # validation batch size\n","      predicted_s_o[i] = torch.autograd.functional.hessian(self.forward, x[i], create_graph=True, strict=True)\n","\n","    loss = alpha * self.loss(y, predicted_y) + beta * self.loss( f_o, predicted_f_o) + delta * self.loss(s_o,  predicted_s_o)\n","    self.log('val_loss', loss) # no optimization required for\n","   # print( loss) \n","    return loss\n","\n","  def configure_optimizers(self):\n","    return torch.optim.Adam(self.parameters(), lr=1e-2)\n"],"execution_count":58,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":460,"referenced_widgets":["c6f97d7487134944b46695efc7f5561b","5ef9bd2c1ac74bfeadaab11c5804acb1","35f555a9c36e4b6ea25b64b98d489f66","4fb61f84e6ad48668ee032d100b82554","a2e2719e79ae4856b971316a455449da","da2936ade49c4eeb8f244f21c009a0e4","fa11c0d35c804931a2e4d9adf03d52b8","6982768b818e4479900eaaffe6848edc","96ba0537cb6e4f14b84522fc12c97b0a","58652738bfde418fb1ca8f6ede3fd5fe","12dee8206fd84192971fe2c0ae97b3f8","a6ead4e4f498429b84582333b0c15360","eba887288f484b5db7d50bf98345dc3b","97e59e0dead6458c9e2c39a982290f5b","7c94a8f0142d4b67b781f40209cafb1f","7dd3863a5fe04a0cbfffe66e51de75b5"]},"id":"1NMNH9ZRJ_Ya","executionInfo":{"status":"ok","timestamp":1628552225801,"user_tz":-60,"elapsed":2661,"user":{"displayName":"Akshay Parmar","photoUrl":"","userId":"04463184220884570036"}},"outputId":"8f8b6705-62b6-4713-b1eb-6097dcc3a549"},"source":["trainer = pl.Trainer(max_epochs= 300)\n","# https://www.machinecurve.com/index.php/question/how-to-set-number-of-epochs-in-pytorch-lightning/\n","model = SecondOrderNetwork() # Trained. \n","\n","trainer.fit(model, train_loader, val_loader) \n","\n","# take lograithems "],"execution_count":62,"outputs":[{"output_type":"stream","text":["GPU available: False, used: False\n","TPU available: False, using: 0 TPU cores\n","IPU available: False, using: 0 IPUs\n","\n","  | Name     | Type     | Params\n","--------------------------------------\n","0 | layer_1  | Linear   | 250   \n","1 | layer_2  | Linear   | 1.5 K \n","2 | layer_3  | Linear   | 31    \n","3 | softplus | Softplus | 0     \n","4 | loss     | MSELoss  | 0     \n","--------------------------------------\n","1.8 K     Trainable params\n","0         Non-trainable params\n","1.8 K     Total params\n","0.007     Total estimated model params size (MB)\n"],"name":"stderr"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c6f97d7487134944b46695efc7f5561b","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validation sanity check', layout=Layout…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\r"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/data_loading.py:323: UserWarning: The number of training samples (8) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n","  f\"The number of training samples ({self.num_training_batches}) is smaller than the logging interval\"\n"],"name":"stderr"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"96ba0537cb6e4f14b84522fc12c97b0a","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["tensor(1936.6995, grad_fn=<AddBackward0>)\n","tensor(1829.4332, grad_fn=<AddBackward0>)\n","tensor(1895.9531, grad_fn=<AddBackward0>)\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py:1047: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n","  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"z-okuhxVKjBH"},"source":[""],"execution_count":null,"outputs":[]}]}